{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b536339d-18ff-4b7c-a26a-3c3ee6a4dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imdb\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "ia = imdb.IMDb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94159085-7637-4c88-9cb5-38a0eaeac294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otrzymanie comentarzów \n",
    "def get_imdb_reviews(movie_title):\n",
    "    url = f\"https://www.imdb.com/title/{movie_title}/reviews\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    review_containers = soup.find_all(\"div\", class_=\"lister-item-content\")\n",
    "\n",
    "    reviews = []\n",
    "    for container in review_containers:\n",
    "        review_text = container.find(\"div\", class_=\"text\").text.strip()\n",
    "        reviews.append(review_text)\n",
    "\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dc51674-bb80-4a46-a1ed-a79b129590a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    movie_ids = ['tt1375666']  # Id filmu dla treningu\n",
    "    reviews = []\n",
    "    for movie_id in movie_ids:\n",
    "        reviews.extend(get_imdb_reviews(movie_id))\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "439c2408-d412-4edd-a063-20226897be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = load_data()\n",
    "# ocena comentarza (0 - zly 1 - dobry)\n",
    "labels = np.array([1, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
    "                   0, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
    "                   1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a68c87c-e932-46c1-a682-71ffbb625987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie i trening modelu\n",
    "tokenizer = Tokenizer(num_words=10000)  # Ograniczenie słownictwa do 10 000 najczęściej używanych słów.\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "sequences = tokenizer.texts_to_sequences(reviews)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=100)  # Ogranicz długość sekwencji do 100 słów\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfa90aba-0e83-43f0-b208-8618b797b6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 15:52:23.696529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-26 15:52:24.009555: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-26 15:52:24.009854: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-26 15:52:24.019175: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-26 15:52:24.019287: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-26 15:52:24.019343: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-26 15:52:28.040614: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-26 15:52:28.042603: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-26 15:52:28.042717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-26 15:52:28.042905: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-26 15:52:28.043275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1268 MB memory:  -> device: 0, name: NVIDIA GeForce MX150, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(10000, 16, input_length=100),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94af0809-9019-4694-9a00-1efb8c5d17fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 15:52:33.058295: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f6b4c016500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-26 15:52:33.058426: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce MX150, Compute Capability 6.1\n",
      "2023-05-26 15:52:33.170474: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-26 15:52:34.478166: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-05-26 15:52:35.999336: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-26 15:52:36.413497: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 9s 9s/step - loss: 0.6928 - accuracy: 0.6000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6919 - accuracy: 0.7600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6c29b275e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(padded_sequences, labels, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c06f064f-d29d-424c-900c-64ec81f18343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja analizy filmu\n",
    "def analyze_movie(movie_id):\n",
    "    reviews = get_imdb_reviews(movie_id)\n",
    "    sequences = tokenizer.texts_to_sequences(reviews)\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=100)\n",
    "    predictions = model.predict(padded_sequences)\n",
    "    average_sentiment = predictions.mean()\n",
    "    return average_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df3334f6-8a4e-4c57-bcb4-f6ff88a7e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imdb_movie_id(movie_title):\n",
    "    movies = imdb.search_movie(movie_title)\n",
    "    movie = movies[0]\n",
    "    movie_id = movie.getID()\n",
    "    return 'tt' + movie_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b95d903e-de0e-4175-a9db-730f05561e47",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'imdb' has no attribute 'search_movie'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mToy Story\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m mv \u001b[38;5;241m=\u001b[39m \u001b[43mget_imdb_movie_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#movie_title = get_imdb_movie_title_by_id(movie_id)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m sentiment \u001b[38;5;241m=\u001b[39m analyze_movie(mv)\n",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m, in \u001b[0;36mget_imdb_movie_id\u001b[0;34m(movie_title)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_imdb_movie_id\u001b[39m(movie_title):\n\u001b[0;32m----> 2\u001b[0m     movies \u001b[38;5;241m=\u001b[39m \u001b[43mimdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_movie\u001b[49m(movie_title)\n\u001b[1;32m      3\u001b[0m     movie \u001b[38;5;241m=\u001b[39m movies[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m     movie_id \u001b[38;5;241m=\u001b[39m movie\u001b[38;5;241m.\u001b[39mgetID()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'imdb' has no attribute 'search_movie'"
     ]
    }
   ],
   "source": [
    "title = 'Toy Story'\n",
    "mv = get_imdb_movie_id(title)\n",
    "#movie_title = get_imdb_movie_title_by_id(movie_id)\n",
    "sentiment = analyze_movie(mv)\n",
    "if sentiment > 0.5:\n",
    "    print(f\"The movie '{title}' is recommended.\")\n",
    "else:\n",
    "    print(f\"The movie '{title}' is not recommended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5763723-3986-47cc-8688-53b5e0d4d0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
